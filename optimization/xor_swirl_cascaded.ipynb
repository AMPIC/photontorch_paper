{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swirl Reservoir + Complex Readout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# main imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# photontorch\n",
    "import photontorch as pt\n",
    "from photontorch_rc import PhotonicSwirlNetwork\n",
    "from torch.nn import Parameter\n",
    "from photontorch.torch_ext.nn import Buffer\n",
    "\n",
    "# other\n",
    "from tqdm import trange # progress bars\n",
    "from scipy.signal import butter, lfilter # bit smoothing\n",
    "\n",
    "# mpl style context manager\n",
    "custom_style = lambda : plt.style.context(os.path.abspath('custom.mplstyle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters\n",
    "dt = 1e-12 # simulation timestep\n",
    "bitrate = 50e9 # bps\n",
    "samplerate = 1/dt # new sampling rate\n",
    "power = 1e-3 #[W]\n",
    "S = int(samplerate/bitrate+0.5) # timesteps per bit (sampling points per bit)\n",
    "\n",
    "# training parameters\n",
    "num_train_bits = 1000\n",
    "num_test_bits = 10000\n",
    "learning_rate=0.1\n",
    "train_bits_seed = 23\n",
    "test_bits_seed = 42\n",
    "batch_size = 10 # number of parallel simulations to run during training\n",
    "latencies = np.array([2.1]) # how many bits delay\n",
    "\n",
    "# source and detector locations:\n",
    "height = 3\n",
    "width = 6\n",
    "sources_at = [1, 8, 15, 22, 29, 35]\n",
    "detectors_at = slice(None) # all nodes are output nodes\n",
    "trainable_nodes = []#[6, 11, 17, 22, 28, 33]\n",
    "\n",
    "# default computation device (cuda or cpu)\n",
    "device = 'cuda'\n",
    "\n",
    "# set general seed\n",
    "torch.manual_seed(7)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tplot(dt, field, **kwargs):\n",
    "    ''' useful visualization function '''\n",
    "    if torch.is_tensor(field):\n",
    "        field = field.data.detach().cpu().numpy()\n",
    "        if field.shape[0]==2:\n",
    "            field = field[0] + 1j*field[1]\n",
    "    t = 1e12*np.arange(field.shape[0])*dt + kwargs.pop('start', 0)\n",
    "    plt.xlabel('time [ps]')\n",
    "    return plt.plot(t, np.real(field), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bits(num_bits, seed=None):\n",
    "    ''' generate a random bit stream '''\n",
    "    if seed is not None:\n",
    "        r = np.random.RandomState(seed=seed)\n",
    "    else:\n",
    "        r = np.random\n",
    "    bits = r.rand(num_bits) > 0.5\n",
    "    bits[0] = 1 # no use having 0-bits in front of the stream\n",
    "    return bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitstream(bits, bitrate=bitrate, samplerate=samplerate):\n",
    "    bitstream = np.vstack([bits]*int(samplerate/bitrate+0.5)).T.ravel()\n",
    "    border_freq = 150e9 # way too high, but we use this just to smoothen the bits\n",
    "    filter_order = 1\n",
    "    cutoff = border_freq / (0.5*samplerate)\n",
    "    b, a = butter(filter_order, cutoff, btype='lowpass', analog=False)\n",
    "    bitstream = lfilter(b, a, bitstream, axis=0)\n",
    "    bitstream = torch.tensor(bitstream, dtype=torch.get_default_dtype(), device=device)\n",
    "    return bitstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = generate_bits(10)\n",
    "stream = bitstream(bits, bitrate, samplerate)\n",
    "tplot(dt, stream)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor(bits):\n",
    "    return (np.hstack([bits,[0]])^np.hstack([[0],bits]))[:-1]\n",
    "def xor2(bits):\n",
    "    return (np.hstack([bits,[0,0]])^np.hstack([[0,0],bits]))[:-2]\n",
    "def xor3(bits):\n",
    "    output = np.hstack([bits,[0,0]])\n",
    "    output ^= np.hstack([[0], bits, [0]])\n",
    "    output ^= np.hstack([[0,0], bits])\n",
    "    return output[:-2]\n",
    "\n",
    "xor = xor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = generate_bits(10)\n",
    "# target_bits = xor(bits)\n",
    "target_bits = xor(bits)\n",
    "stream = bitstream(bits)\n",
    "target_stream = bitstream(target_bits)\n",
    "tplot(dt,stream)\n",
    "tplot(dt,target_stream)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train: Weight First, Detect Last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_error_rate(y_true, y_pred, bit_threshold=0.5):\n",
    "    return torch.mean(((y_true > bit_threshold) != (y_pred > bit_threshold)).float())\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return torch.mean((y_true-y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_bits = generate_bits(num_train_bits, seed=train_bits_seed)\n",
    "train_stream = bitstream(train_bits)\n",
    "train_target = bitstream(xor(train_bits))\n",
    "\n",
    "# Test set\n",
    "test_bits = generate_bits(num_test_bits, seed=test_bits_seed)\n",
    "test_stream = bitstream(test_bits)\n",
    "test_target = bitstream(xor(test_bits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Latencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is way more efficient to simultaneously train for multiple latencies with the data splitted into different batches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create different shifted versions of the bitstream for each latency\n",
    "train_streams = []\n",
    "train_targets = []\n",
    "for i, latency in enumerate(latencies):\n",
    "    L = int(latency*samplerate/bitrate + 0.5)\n",
    "    M = int(max(latencies)*samplerate/bitrate + 0.5) + 1\n",
    "    train_streams.append(train_stream[L:-M+L])\n",
    "    train_targets.append(train_target[:-M])\n",
    "train_streams = torch.stack(train_streams, 1)\n",
    "train_targets = torch.stack(train_targets, 1)\n",
    "\n",
    "# next, we split this bitstream into batches to speed up the training\n",
    "train_stream_batches = torch.split(train_streams, train_streams.shape[0]//batch_size, 0)[:-1]\n",
    "train_target_batches = torch.split(train_targets, train_targets.shape[0]//batch_size, 0)[:-1]\n",
    "train_streams = torch.stack(train_stream_batches, 1) # shape = (timesteps_per_batch, #batches, #latencies)\n",
    "train_targets = torch.stack(train_target_batches, 1) # shape = (timesteps_per_batch, #batches, #latencies)\n",
    "\n",
    "# print out resulting shape of the tensor used for training:\n",
    "print('resulting shape: (timesteps_per_batch=%i, batch_size=%i, #latencies=%i)'%train_streams.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the reservoir module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir(torch.nn.Module):\n",
    "    def __init__(self, height, width, sources_at, detectors_at):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        sources_at = np.arange(2*width*height)[sources_at]\n",
    "        detectors_at = np.arange(2*width*height)[detectors_at]\n",
    "            \n",
    "        # Input weights (random phase + division of power; not trainable)\n",
    "        input_dim = 1\n",
    "        output_dim = len(sources_at)\n",
    "        phase_in = 2*np.pi*torch.rand(input_dim, output_dim, device=device)\n",
    "        self.register_buffer('rWin', (1.0/output_dim)*torch.cos(phase_in))\n",
    "        self.register_buffer('iWin', (1.0/output_dim)*torch.sin(phase_in))\n",
    "        \n",
    "        self.sources_at1 = list(sources_at[sources_at<width*height])\n",
    "        self.num_sources1 = len(self.sources_at1)\n",
    "        self.sources_at2 = list(sources_at[sources_at>=width*height] - width*height)\n",
    "        \n",
    "        self.detectors_at1 = list(detectors_at[detectors_at<width*height])\n",
    "        self.detectors_at2 = list(detectors_at[detectors_at>=width*height]-width*height)\n",
    "        \n",
    "        # first reservoir\n",
    "        self.reservoir1 = PhotonicSwirlNetwork(\n",
    "            height=height,\n",
    "            width=width,\n",
    "            node_delay=int(samplerate/bitrate+0.5)*dt,\n",
    "            signal_freq=samplerate,\n",
    "            loss_dB=1.0,\n",
    "            sources_at = self.sources_at1,\n",
    "            detectors_at = self.detectors_at1,\n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "        # intermediate weights\n",
    "        self.rV = torch.nn.Parameter(torch.rand((width*height,width*height), dtype=torch.float32, device=device))\n",
    "        self.iV = torch.nn.Parameter(torch.rand((width*height,width*height), dtype=torch.float32, device=device))\n",
    "        \n",
    "        # second reservoir\n",
    "        self.reservoir2 = PhotonicSwirlNetwork(\n",
    "            height=height,\n",
    "            width=width,\n",
    "            node_delay=int(samplerate/bitrate+0.5)*dt,\n",
    "            signal_freq=samplerate,\n",
    "            loss_dB=1.0,\n",
    "            sources_at = list(range(width*height)),\n",
    "            detectors_at = self.detectors_at2,\n",
    "        ).to(device)\n",
    "        \n",
    "        # trainable nodes\n",
    "        for i in np.arange(2*height*width)[trainable_nodes]:\n",
    "            res_idx = i//(height*width) + 1\n",
    "            idx = i - (res_idx==2)*width*height\n",
    "            wg = getattr(self, 'reservoir%i'%res_idx).components['waveguide%i'%idx]\n",
    "            wg.phase = torch.nn.Parameter(wg._buffers.pop('phase').data)\n",
    "        \n",
    "        # output weights; random, complex and trainable\n",
    "        self.rW = Parameter(torch.rand((len(detectors_at)), dtype=torch.float32, device=device))\n",
    "        self.iW = Parameter(torch.rand((len(detectors_at)), dtype=torch.float32, device=device))\n",
    "        \n",
    "        # detector\n",
    "        self.detector = pt.Photodetector(bitrate=bitrate, dt=dt).to(device)\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.reservoir2.initialize()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # get environment\n",
    "            env = pt.current_environment()\n",
    "            self.reservoir1.initialize()\n",
    "\n",
    "            # check if input is complex\n",
    "            if x.shape[0] != 2:\n",
    "                x = torch.stack([x, torch.zeros_like(x)], 0)\n",
    "\n",
    "            # x should have shape (2, timesteps_per_batch, batch_size, #latencies)\n",
    "            _, a, b, c = x.shape\n",
    "\n",
    "            # batch together batches and latencies\n",
    "            batch_size = b*c\n",
    "            x = x.view(2, a, batch_size)\n",
    "\n",
    "            # add CW bias [disabled]\n",
    "            #x = torch.stack([x, torch.zeros_like(x)], -1)\n",
    "            # add single input dim instead:\n",
    "            x = x[...,None]\n",
    "\n",
    "            # apply Win2res:\n",
    "            x = torch.stack([\n",
    "                x[0]@self.rWin - x[1]@self.iWin,\n",
    "                x[0]@self.iWin + x[1]@self.rWin,\n",
    "            ], 0)\n",
    "            \n",
    "            x1 = x[..., :self.num_sources1]\n",
    "            x2 = x[..., self.num_sources1:]\n",
    "\n",
    "            # bring tensor in standard shape (add dim for wls etc...)\n",
    "            x1 = self.reservoir1.handle_source(x1)\n",
    "\n",
    "            # create tensor to store detected:\n",
    "            detected1 = torch.zeros((2, a, 1, self.reservoir1.num_detectors, batch_size), device=device)\n",
    "            detected2 = torch.zeros((2, a, 1, self.reservoir2.num_detectors, batch_size), device=device)\n",
    "\n",
    "            # create buffer for the simulation\n",
    "            buffer1 = self.reservoir1.simulation_buffer(batch_size)\n",
    "            buffer2 = self.reservoir2.simulation_buffer(batch_size)\n",
    "\n",
    "            # solve\n",
    "            for i, t in enumerate(env.time):\n",
    "                det1, buffer1 = self.reservoir1.step(t, x1[:,i], buffer1)\n",
    "                detected1[:,i] = det1\n",
    "        \n",
    "        # start tracking gradients from here on:\n",
    "\n",
    "        r = torch.matmul(torch.transpose(detected1[0], -1, -2), self.rV) \n",
    "        r -= torch.matmul(torch.transpose(detected1[1], -1, -2), self.iV)\n",
    "        i = torch.matmul(torch.transpose(detected1[0], -1, -2), self.iV) \n",
    "        i += torch.matmul(torch.transpose(detected1[1], -1, -2), self.rV)\n",
    "\n",
    "        #x = torch.transpose(torch.stack([r, i], 0), -1, -2)\n",
    "        x = torch.transpose(torch.stack([r, torch.zeros_like(i)], 0), -1, -2)\n",
    "        #x = torch.transpose(self.detector(r**2 + i*2), -1, -2)\n",
    "\n",
    "\n",
    "        #x = torch.transpose(torch.sqrt(r**2+i**2), -1, -2)\n",
    "        x = self.reservoir2.handle_source(x)\n",
    "        x2 = torch.transpose(x2[:,:,None], -1, -2) # add dimension for wavelength\n",
    "        x[:,:,:,self.sources_at2,:] += x2\n",
    "\n",
    "        for i, t in enumerate(env.time):\n",
    "            det2, buffer2 = self.reservoir2.step(t, x[:,i], buffer2)\n",
    "            detected2[:,i] = det2\n",
    "\n",
    "        detected = torch.transpose(torch.cat([detected1, detected2], -2), -1, -2)\n",
    "        \n",
    "        r = torch.matmul(detected[0], self.rW) \n",
    "        r -= torch.matmul(detected[1], self.iW)\n",
    "        i = torch.matmul(detected[0], self.iW) \n",
    "        i += torch.matmul(detected[1], self.rW)\n",
    "        return self.detector(r**2 + i**2).view(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoir = Reservoir(height, width, sources_at, detectors_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = {\n",
    "    #'0':[],\n",
    "    #'2':[17,28],\n",
    "    '6':[6,11,17,22,28,33],\n",
    "    #'A':slice(None),\n",
    "}\n",
    "suffix = 'xor'\n",
    "if xor is xor2: suffix = 'xor2'\n",
    "elif xor is xor3: suffix = 'xor3'\n",
    "for mode, trainable_nodes in modes.items():\n",
    "    reservoir = Reservoir(height, width, sources_at, detectors_at)\n",
    "    # train loop\n",
    "    train_steps = trange(60) # tqdm range: range with progress bar\n",
    "    losses = []\n",
    "    with pt.Environment(t=np.arange(train_streams.shape[0])*dt, wl=1.55e-6, enable_grad=True) as env:\n",
    "        for _ in train_steps:\n",
    "            # reset gradients:\n",
    "            reservoir.optimizer.zero_grad()\n",
    "\n",
    "            # get prediction\n",
    "            p = reservoir(train_streams)\n",
    "\n",
    "            # we calculate a different loss for each latencies:\n",
    "            loss = ((train_targets-p)**2).mean(0).mean(0)\n",
    "\n",
    "            # we find the best latency, and only update the weights\n",
    "            # of the readout layer according to this loss:\n",
    "            best_index = torch.argmin(loss)\n",
    "            min_loss = loss[best_index]\n",
    "\n",
    "            # add penalty for high weights\n",
    "            min_loss = min_loss + 1e-3*torch.sum(reservoir.rW**2 + reservoir.iW**2)\n",
    "\n",
    "            min_loss.backward()\n",
    "            reservoir.optimizer.step()\n",
    "            \n",
    "            losses.append(min_loss.item())\n",
    "\n",
    "            # keep track of the loss\n",
    "            # the loss might jump around in the beginning before the\n",
    "            # optimal latency is found\n",
    "            train_steps.set_postfix(mse=min_loss.item())\n",
    "\n",
    "            # free up GPU memory\n",
    "            del loss, p\n",
    "    np.save('reservoir_losses/_cascres%s_%s.npy'%(mode, suffix), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimal parameters\n",
    "with pt.Environment(t=np.arange(train_streams.shape[0])*dt, wl=1.55e-6, enable_grad=False):\n",
    "    idx = best_index.item()\n",
    "    latency = latencies[idx]\n",
    "    print(f\"latency: {latency}\")\n",
    "    mse = mean_squared_error(train_targets[:,:,idx:idx+1],\n",
    "                             reservoir(train_streams[:,:,idx:idx+1]))\n",
    "\n",
    "print('best latency = %.4f\\nbest mse (valid) = %.4f'%(latency, mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = int(latency*samplerate/bitrate + 0.5)\n",
    "S = int(samplerate/bitrate+0.5)\n",
    "\n",
    "idx = best_index.item()\n",
    "shifted_test_stream = test_stream[L:]\n",
    "shifted_test_target = test_target[:-L]\n",
    "    \n",
    "with pt.Environment(t=np.arange(shifted_test_stream.shape[0])*dt, wl=1.55e-6, enable_grad=False):\n",
    "    shifted_test_prediction = reservoir(shifted_test_stream[:, None, None])[:,0,0]\n",
    "    mse = mean_squared_error(shifted_test_target, shifted_test_prediction)\n",
    "    ber = bit_error_rate(shifted_test_target[5*S//2:-3*S//2:S], shifted_test_prediction[5*S//2:-3*S//2:S], bit_threshold=0.5)\n",
    "        \n",
    "print(ber.item(), mse.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(shifted_test_prediction[500:1000].data.cpu().numpy())\n",
    "plt.plot(shifted_test_target[500:1000].data.cpu().numpy())\n",
    "plt.plot([-10, 510], [0.5,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the weights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "W = (reservoir.rW[0,:,0].data.cpu().numpy() + 1j*reservoir.iW[0,:,0].data.cpu().numpy())[:,None]\n",
    "U, S, V = np.linalg.svd(W, full_matrices=False)\n",
    "reservoir.rW.data[0,:,:] = torch.tensor(np.real(U), dtype=torch.float32, device=device)\n",
    "reservoir.iW.data[0,:,:] = torch.tensor(np.imag(U), dtype=torch.float32, device=device)\n",
    "print(S)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the detected power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pt.Environment(t=np.arange(test_stream.shape[0])*dt, wl=1.55e-6):\n",
    "    detected = reservoir(test_stream[:,None,None])[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('reservoir_losses/test_stream_casc_%s'%suffix, test_stream.data.cpu().numpy())\n",
    "np.save('reservoir_losses/test_target_casc_%s'%suffix, test_target.data.cpu().numpy())\n",
    "np.save('reservoir_losses/detected_casc_%s'%suffix, detected.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Output\n",
    "c1 = 'grey'\n",
    "c2 = 'C3'\n",
    "test_stream = np.load('reservoir_losses/test_stream_casc_%s.npy'%suffix)\n",
    "test_target = np.load('reservoir_losses/test_target_casc_%s.npy'%suffix)\n",
    "detected = np.load('reservoir_losses/detected_casc_%s.npy'%suffix)\n",
    "with custom_style():\n",
    "    plt.figure(figsize=4*np.array([1,0.37]))\n",
    "    tplot(dt, test_target, label='target', color=c1, ls='--')\n",
    "    plt.ylim(0, 1.25)\n",
    "    plt.yticks([0, 1])\n",
    "    plt.tick_params('y', colors=c1)\n",
    "    plt.ylabel('Target', color=c1)\n",
    "    plt.xlim(100,1100)\n",
    "    plt.xticks([100,600,1100],['0','500','1000'])\n",
    "    plt.twinx()\n",
    "    tplot(dt, detected, start=-latency*samplerate/bitrate*dt*1e12, label='output', color=c2)\n",
    "    #plt.ylim(0, 0.125)\n",
    "    plt.ylabel('Ouput [mW]', color=c2)\n",
    "    plt.tick_params('y', colors=c2)\n",
    "    plt.tight_layout()\n",
    "    #plt.figlegend(loc='upper center', ncol=2)\n",
    "    # plt.savefig('../figures/xor_swirl.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|mse| 0     | F     | A     |\n",
    "|---|-------|-------|-------|\n",
    "| 1 | - | - | - |\n",
    "| 2 | 0.076 | - | - |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
